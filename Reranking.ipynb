{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc482b4",
   "metadata": {},
   "source": [
    "# Reranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede09e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY=\"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d8e1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ddb6f5",
   "metadata": {},
   "source": [
    "### Helper Function to display nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e149cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
    "\n",
    "\n",
    "def visualize_retrieved_nodes(nodes) -> None:\n",
    "    result_dicts = []\n",
    "    for node in nodes:\n",
    "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
    "        result_dicts.append(result_dict)\n",
    "\n",
    "    pretty_print(pd.DataFrame(result_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f74b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.vector_store.retrievers import VectorIndexRetriever\n",
    "from llama_index.indices.query.schema import QueryBundle\n",
    "from llama_index.indices.postprocessor import LLMRerank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fe6af",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df86966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data:folder name\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e9930",
   "metadata": {},
   "source": [
    "## Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f63e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index\n",
    "index = VectorStoreIndex(nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142602ab",
   "metadata": {},
   "source": [
    "## Write your Promt and query the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f059277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" what is NLP\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bdbe333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>NLP stands for natural language processing. It is a field of study that involves the use of computer algorithms to analyze and understand human language.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(prompt)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c2ef9",
   "metadata": {},
   "source": [
    "## Get K top similar nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b443e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "  index=index,\n",
    "  similarity_top_k=4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1daefb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve top-k most similar nodes\n",
    "query_bundle = QueryBundle(prompt) \n",
    "retrieved_nodes = retriever.retrieve(query_bundle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b735845",
   "metadata": {},
   "source": [
    "#### No-rerank retrieved nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f11f3fef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787408</td>\n",
       "      <td>Many great models are being introduced  <br>now a days that are h aving quite a heavy impact on the field on NLP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785544</td>\n",
       "      <td>Sentiment analysis is a natural  language  <br>processing (NLP) technique used to determine whether data is positive, negative or neutral.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.783839</td>\n",
       "      <td>NLTK library as of now gives an execution of the Po rter <br>stemmer computation in the nltk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782984</td>\n",
       "      <td>Opinion Analysis is an NLP and data extract ion <br>task that expects to acquire essayists felling <br>communicated in certain or negative remarks, <br>questions, and demands by breaking down an enormous  <br>number of archives.  <br></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_retrieved_nodes(retrieved_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e51892",
   "metadata": {},
   "source": [
    "## Rerank the nodes using \"LLMRerank\" and get K top reranked nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19a4580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure reranker\n",
    "# choice_batch_size = number of nodes passed to LLMRerank to assign a score at one time\n",
    "# top_n = number of nodes selected\n",
    "reranker = LLMRerank(choice_batch_size=1, top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8d42d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rerank retrieved nodes\n",
    "retrieved_nodes2 = reranker.postprocess_nodes(retrieved_nodes, query_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67dc16",
   "metadata": {},
   "source": [
    "#### LLMRerank retrieved nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9faa3f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Sentiment analysis is a natural  language  <br>processing (NLP) technique used to determine whether data is positive, negative or neutral.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Opinion Analysis is an NLP and data extract ion <br>task that expects to acquire essayists felling <br>communicated in certain or negative remarks, <br>questions, and demands by breaking down an enormous  <br>number of archives.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Many great models are being introduced  <br>now a days that are h aving quite a heavy impact on the field on NLP.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_retrieved_nodes(retrieved_nodes2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c478c2",
   "metadata": {},
   "source": [
    "## Cohere Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2767c02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833866</td>\n",
       "      <td>Sentiment analysis is a natural  language  <br>processing (NLP) technique used to determine whether data is positive, negative or neutral.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571886</td>\n",
       "      <td>NLTK library as of now gives an execution of the Po rter <br>stemmer computation in the nltk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526617</td>\n",
       "      <td>Opinion Analysis is an NLP and data extract ion <br>task that expects to acquire essayists felling <br>communicated in certain or negative remarks, <br>questions, and demands by breaking down an enormous  <br>number of archives.  <br></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Method1\n",
    "\n",
    "import cohere\n",
    "from llama_index.indices.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# Initialize the Cohere client\n",
    "cohere_rerank  = CohereRerank(api_key='',top_n=3)\n",
    "\n",
    "retrieved_nodes1 = cohere_rerank.postprocess_nodes(retrieved_nodes, query_bundle)\n",
    "\n",
    "visualize_retrieved_nodes(retrieved_nodes1)\n",
    "# Rerank the retrieved nodes\n",
    "#results = client.rerank(model=\"rerank-english-v2.0\", query=promt, documents=documents, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c8135c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "relevance Score 0.98884195\n",
      "################\n",
      "RerankResult<document['text']: International Journal of Trend in Scientific Researc h and Development (IJTSRD) @  www.ijtsrd.com  eISSN: 2456-6470 \n",
      "@ IJTSRD | Unique Paper ID - IJTSRD23375   | Volume – 3 | Issue – 3 | Mar-Apr 2019 Page: 1371  2. Develop a method for automatic sentiment analysi s of \n",
      "Twitter messages. \n",
      "Opinion Mining and Sentiment Analysis, sentiment an alysis \n",
      "involves automatic analysis of opinions and emotive  lexicons \n",
      "expressed in a text. In the analysis of a text tona lity, it is \n",
      "considered that text information on the Internet is  divided \n",
      "into two classes: facts and opinions. The definitio n of an \n",
      "opinion is a key concept. Opinions are divided into  two \n",
      "types:  \n",
      "1. Simple opinion.  \n",
      "2. Comparison \n",
      " \n",
      "A simple opinion contains the statement of an author  about \n",
      "one entity. It can be stated directly: “I was pleas antly \n",
      "surprised with the furniture assembly quality”, or impl icitly: \n",
      "“After the treatment, my health became stronger”. I n both \n",
      "cases, a simple opinion usually has a positive or ne gative \n",
      "sentiment. In the analysis of the tonality of a tex t, the \n",
      "following formal definition is given for the first type of \n",
      "opinion: a tuple of five elements (entity, feature, sentiment \n",
      "value, holder, time) is called a simple opinion, wh ere entity is \n",
      "the object about whose aspect (feature) the author ( holder) \n",
      "made an opinion at the time (time). \n",
      " \n",
      " There are 3 types of emotions (sentiment value): po sitive, \n",
      "negative and neutral. Neutral emotion means that the  text \n",
      "does not contain an emotional component. Entity is a person, \n",
      "organization, event, product or topic of discussion. \n",
      "Therefore, in various publications, entity is also c alled object \n",
      "or topic. Often, an entity can be represented as a hierarchical \n",
      "tree of components and sub-components.   \n",
      " \n",
      "PROPOSED SYSTEM \n",
      " \n",
      "Following are the features Included  \n",
      " \n",
      "Step 1: Data Collection : \n",
      "Collect the data from any social website. Data used in this \n",
      "study are online product reviews collected from Twit ter. \n",
      "Experiments for both sentence-level categorization and \n",
      "review-level categorization are performed with prom ising \n",
      "outcomes. At last, we also give insight into our fut ure work \n",
      "on sentiment analysis. \n",
      " \n",
      "Step 2:  Data Pre-processing :  \n",
      "It removes all unnecessary tweets like re-tweets, re plies and \n",
      "also tweets which are not expressing any emotions. Stop \n",
      "words removal, and the entire thing which is implem ented in \n",
      "our base paper \"student learning\". \n",
      " \n",
      "Step 3: Feature Extraction : \n",
      " Here we will try different combinations of feature s like Uni-\n",
      "grams, POS tagging, twitter specific features etc..  Every word \n",
      "of a sentence has its syntactic role that defines h ow the word \n",
      "is used. The syntactic roles are also known as the p arts of \n",
      "speech. There are 8 parts of speech in English: the  verb, the \n",
      "noun, the pronoun, the adjective, the adverb, the pre position, \n",
      "the conjunction, and the interjection. In natural l anguage \n",
      "processing, part-of-speech (POS) taggers have been developed to classify words based on their parts of  speech. \n",
      "For sentiment analysis, a POS tagger is very useful because of \n",
      "the following two reasons:  \n",
      "1)  Words like nouns and pronouns usually do not contain \n",
      "any sentiment. It is able to filter out such words wi th \n",
      "the help of a POS tagger. \n",
      "2)  A POS tagger can also be used to distinguish words th at \n",
      "can be used in different parts of speech. For insta nce, as \n",
      "a verb, “enhanced\" may conduct different amount of \n",
      "sentiment as being of an adjective. The POS tagger used \n",
      "for this research is a max-entropy POS tagger \n",
      "developed for the Penn Treebank Project., index: 1, relevance_score: 0.98884195>\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "1\n",
      "relevance Score 0.91774607\n",
      "################\n",
      "RerankResult<document['text']: The tagger  is \n",
      "able to provide 46 different tags indicating that i t can \n",
      "identify more detailed syntactic roles than only 8.  As an \n",
      "example, Table 1 is a list of all tags for verbs th at has \n",
      "been included in the POS tagger. \n",
      " \n",
      "Step 4: Feature selection: \n",
      " Now we would select the best features. We propose a s et of \n",
      "features listed in Table 4 for our experiments. These  are a \n",
      "total of 50 type of features. We calculate these fe atures for \n",
      "the whole tweet and for the last one-third of the t weet. In \n",
      "total we get 100 additional features. We refer to th ese \n",
      "features as Sent-features throughout the paper. Our feat ures \n",
      "can be divided into three broad categories:  \n",
      " \n",
      "Firstly that are primarily counts of various feature s and \n",
      "therefore the value of the feature is a natural numbe r ∈ N.  \n",
      " \n",
      "Second, features whose value is a real number ∈ R. These are \n",
      "primarily features that capture the score retrieved f rom DAL.  \n",
      " \n",
      "Thirdly, features whose values are Boolean ∈ B. These  are \n",
      "bag of words, presence of exclamation marks and cap italized \n",
      "text. \n",
      " \n",
      "Each of these broad categories is divided into two \n",
      "subcategories: Polar features and Non-polar features.  We \n",
      "refer to a feature as polar if we calculate its prio r polarity \n",
      "either by looking it up in DAL (extended through Word  Net) \n",
      "or in the emoticon dictionary. All other features w hich are \n",
      "not associated with any prior polarity fall in the Non-polar \n",
      "category. Each of Polar and Non-polar features is f urther \n",
      "subdivided into two categories: POS and Other. POS r efers to \n",
      "features that capture statistics about parts-of-speech  of \n",
      "words and other refers to all other types of featur es.  \n",
      " \n",
      "Step 5: Classification \n",
      "Here we will compare Naive Bayes .The Naïve Bayesian  \n",
      "classifier works as follows: Suppose that there exi st a set of \n",
      "training data, D, in which each tuple is represented by an n-\n",
      "dimensional feature vector, X=x1 ,x2,.., xn, indicating n \n",
      "measurements made on the tuple from n attributes or \n",
      "features. Assume that there are m classes, C1, C2,..., Cm. Given \n",
      "a tuple X, the classifier will predict that X belongs to Ci if \n",
      "and only if: P (Ci|X) > P (Cj|X), where i,j∈[1, m] and i ≠j. P(Ci|X) \n",
      "is computed as: \n",
      "P(Ci|X)=∏k= 1nP (xk|Ci) \n",
      " \n",
      "Step 6: Comparison of Results : \n",
      "As the last step we will compare the results.  \n",
      "2.1 Comparison of models for this task the unigram m odel \n",
      "achieves a gain of 23.25% over chance baseline. Tab le 8 \n",
      "compares the performance of our three models. We rep ort \n",
      "mean and standard deviation of 5-fold test accuracy . We \n",
      "observe that the tree kernels outperform the unigram and, index: 0, relevance_score: 0.91774607>\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Method2\n",
    "\n",
    "#compares the semantic information in the query and the initial search results\n",
    "import cohere\n",
    "\n",
    "# Initialize the Cohere client\n",
    "client = cohere.Client(api_key='')\n",
    "\n",
    "\n",
    "# Convert the retrieved nodes to a list of responses\n",
    "responses = [node.text for node in retrieved_nodes]\n",
    "\n",
    "# Rerank the responses\n",
    "reranked_responses = client.rerank(\n",
    "   model=\"rerank-english-v2.0\",\n",
    "   query=prompt,\n",
    "   documents=responses,\n",
    "   top_n=5\n",
    ")\n",
    "for i in range(2):\n",
    "    print(i)\n",
    "    print(\"relevance Score\",reranked_responses[i].relevance_score)\n",
    "    print(\"################\")\n",
    "    print(reranked_responses[i])\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"---------------------------------------\")\n",
    "# Print the reranked responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcab38",
   "metadata": {},
   "source": [
    "## SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "699f58fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.301733</td>\n",
       "      <td>Sentiment analysis is a natural  language  <br>processing (NLP) technique used to determine whether data is positive, negative or neutral.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.241898</td>\n",
       "      <td>Opinion Analysis is an NLP and data extract ion <br>task that expects to acquire essayists felling <br>communicated in certain or negative remarks, <br>questions, and demands by breaking down an enormous  <br>number of archives.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.069395</td>\n",
       "      <td>Many great models are being introduced  <br>now a days that are h aving quite a heavy impact on the field on NLP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.986939</td>\n",
       "      <td>NLTK library as of now gives an execution of the Po rter <br>stemmer computation in the nltk.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 4.301733\n",
      "#################\n",
      "Sentiment analysis is a natural  language  \n",
      "processing (NLP) technique used to determine whether data is positive, negative or neutral.  \n",
      "\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "SCORE: 1.2418978\n",
      "#################\n",
      "Opinion Analysis is an NLP and data extract ion \n",
      "task that expects to acquire essayists felling \n",
      "communicated in certain or negative remarks, \n",
      "questions, and demands by breaking down an enormous  \n",
      "number of archives.  \n",
      "\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "SCORE: -4.069395\n",
      "#################\n",
      "Many great models are being introduced  \n",
      "now a days that are h aving quite a heavy impact on the field on NLP. \n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "SCORE: -5.986939\n",
      "#################\n",
      "NLTK library as of now gives an execution of the Po rter \n",
      "stemmer computation in the nltk. \n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Uses the cross-encoders from the sentence-transformer package to re-order nodes, and returns the top N nodes.\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "# Initialize the SentenceTransformerRerank postprocessor\n",
    "postprocessor = SentenceTransformerRerank(\n",
    "   model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", \n",
    "   top_n=5\n",
    ")\n",
    "\n",
    "# Rerank the retrieved nodes\n",
    "reranked_nodes4 = postprocessor.postprocess_nodes(nodes=retrieved_nodes, query_bundle=query_bundle)\n",
    "visualize_retrieved_nodes(reranked_nodes4)\n",
    "\n",
    "# Print the reranked nodes\n",
    "for node in reranked_nodes4:\n",
    "    print(\"SCORE:\",node.score)\n",
    "    print(\"#################\")\n",
    "    print(node.text)\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef8d87",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eaad2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    ServiceContext,\n",
    ")\n",
    "service_context = ServiceContext.from_defaults()\n",
    "nodes = service_context.node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "from llama_index.retrievers import BM25Retriever\n",
    "\n",
    "# retireve the top 10 most similar nodes using bm25\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f320a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Node: International Journal of Trend in Scientific Researc h and Development (IJTSRD) @  www.ijtsrd.com  eISSN: 2456-6470 \n",
      "@ IJTSRD | Unique Paper ID - IJTSRD23375   | Volume – 3 | Issue – 3 | Mar-Apr 2019 Page: 1371  2. Develop a method for automatic sentiment analysi s of \n",
      "Twitter messages. \n",
      "Opinion Mining and Sentiment Analysis, sentiment an alysis \n",
      "involves automatic analysis of opinions and emotive  lexicons \n",
      "expressed in a text. In the analysis of a text tona lity, it is \n",
      "considered that text information on the Internet is  divided \n",
      "into two classes: facts and opinions. The definitio n of an \n",
      "opinion is a key concept. Opinions are divided into  two \n",
      "types:  \n",
      "1. Simple opinion.  \n",
      "2. Comparison \n",
      " \n",
      "A simple opinion contains the statement of an author  about \n",
      "one entity. It can be stated directly: “I was pleas antly \n",
      "surprised with the furniture assembly quality”, or impl icitly: \n",
      "“After the treatment, my health became stronger”. I n both \n",
      "cases, a simple opinion usually has a positive or ne gative \n",
      "sentiment. In the analysis of the tonality of a tex t, the \n",
      "following formal definition is given for the first type of \n",
      "opinion: a tuple of five elements (entity, feature, sentiment \n",
      "value, holder, time) is called a simple opinion, wh ere entity is \n",
      "the object about whose aspect (feature) the author ( holder) \n",
      "made an opinion at the time (time). \n",
      " \n",
      " There are 3 types of emotions (sentiment value): po sitive, \n",
      "negative and neutral. Neutral emotion means that the  text \n",
      "does not contain an emotional component. Entity is a person, \n",
      "organization, event, product or topic of discussion. \n",
      "Therefore, in various publications, entity is also c alled object \n",
      "or topic. Often, an entity can be represented as a hierarchical \n",
      "tree of components and sub-components.   \n",
      " \n",
      "PROPOSED SYSTEM \n",
      " \n",
      "Following are the features Included  \n",
      " \n",
      "Step 1: Data Collection : \n",
      "Collect the data from any social website. Data used in this \n",
      "study are online product reviews collected from Twit ter. \n",
      "Experiments for both sentence-level categorization and \n",
      "review-level categorization are performed with prom ising \n",
      "outcomes. At last, we also give insight into our fut ure work \n",
      "on sentiment analysis. \n",
      " \n",
      "Step 2:  Data Pre-processing :  \n",
      "It removes all unnecessary tweets like re-tweets, re plies and \n",
      "also tweets which are not expressing any emotions. Stop \n",
      "words removal, and the entire thing which is implem ented in \n",
      "our base paper \"student learning\". \n",
      " \n",
      "Step 3: Feature Extraction : \n",
      " Here we will try different combinations of feature s like Uni-\n",
      "grams, POS tagging, twitter specific features etc..  Every word \n",
      "of a sentence has its syntactic role that defines h ow the word \n",
      "is used. The syntactic roles are also known as the p arts of \n",
      "speech. There are 8 parts of speech in English: the  verb, the \n",
      "noun, the pronoun, the adjective, the adverb, the pre position, \n",
      "the conjunction, and the interjection. In natural l anguage \n",
      "processing, part-of-speech (POS) taggers have been developed to classify words based on their parts of  speech. \n",
      "For sentiment analysis, a POS tagger is very useful because of \n",
      "the following two reasons:  \n",
      "1)  Words like nouns and pronouns usually do not contain \n",
      "any sentiment. It is able to filter out such words wi th \n",
      "the help of a POS tagger. \n",
      "2)  A POS tagger can also be used to distinguish words th at \n",
      "can be used in different parts of speech. For insta nce, as \n",
      "a verb, “enhanced\" may conduct different amount of \n",
      "sentiment as being of an adjective. The POS tagger used \n",
      "for this research is a max-entropy POS tagger \n",
      "developed for the Penn Treebank Project., Score: 16.011324281151698\n",
      "######################\n",
      "Node: The tagger  is \n",
      "able to provide 46 different tags indicating that i t can \n",
      "identify more detailed syntactic roles than only 8.  As an \n",
      "example, Table 1 is a list of all tags for verbs th at has \n",
      "been included in the POS tagger. \n",
      " \n",
      "Step 4: Feature selection: \n",
      " Now we would select the best features. We propose a s et of \n",
      "features listed in Table 4 for our experiments. These  are a \n",
      "total of 50 type of features. We calculate these fe atures for \n",
      "the whole tweet and for the last one-third of the t weet. In \n",
      "total we get 100 additional features. We refer to th ese \n",
      "features as Sent-features throughout the paper. Our feat ures \n",
      "can be divided into three broad categories:  \n",
      " \n",
      "Firstly that are primarily counts of various feature s and \n",
      "therefore the value of the feature is a natural numbe r ∈ N.  \n",
      " \n",
      "Second, features whose value is a real number ∈ R. These are \n",
      "primarily features that capture the score retrieved f rom DAL.  \n",
      " \n",
      "Thirdly, features whose values are Boolean ∈ B. These  are \n",
      "bag of words, presence of exclamation marks and cap italized \n",
      "text. \n",
      " \n",
      "Each of these broad categories is divided into two \n",
      "subcategories: Polar features and Non-polar features.  We \n",
      "refer to a feature as polar if we calculate its prio r polarity \n",
      "either by looking it up in DAL (extended through Word  Net) \n",
      "or in the emoticon dictionary. All other features w hich are \n",
      "not associated with any prior polarity fall in the Non-polar \n",
      "category. Each of Polar and Non-polar features is f urther \n",
      "subdivided into two categories: POS and Other. POS r efers to \n",
      "features that capture statistics about parts-of-speech  of \n",
      "words and other refers to all other types of featur es.  \n",
      " \n",
      "Step 5: Classification \n",
      "Here we will compare Naive Bayes .The Naïve Bayesian  \n",
      "classifier works as follows: Suppose that there exi st a set of \n",
      "training data, D, in which each tuple is represented by an n-\n",
      "dimensional feature vector, X=x1 ,x2,.., xn, indicating n \n",
      "measurements made on the tuple from n attributes or \n",
      "features. Assume that there are m classes, C1, C2,..., Cm. Given \n",
      "a tuple X, the classifier will predict that X belongs to Ci if \n",
      "and only if: P (Ci|X) > P (Cj|X), where i,j∈[1, m] and i ≠j. P(Ci|X) \n",
      "is computed as: \n",
      "P(Ci|X)=∏k= 1nP (xk|Ci) \n",
      " \n",
      "Step 6: Comparison of Results : \n",
      "As the last step we will compare the results.  \n",
      "2.1 Comparison of models for this task the unigram m odel \n",
      "achieves a gain of 23.25% over chance baseline. Tab le 8 \n",
      "compares the performance of our three models. We rep ort \n",
      "mean and standard deviation of 5-fold test accuracy . We \n",
      "observe that the tree kernels outperform the unigram and, Score: 11.995782913130222\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "top_k_nodes = bm25_retriever._retrieve(query_bundle)\n",
    "\n",
    "print(len(top_k_nodes))\n",
    "# Print the retrieved documents and their scores\n",
    "for node in top_k_nodes:\n",
    "    print(f\"Node: {node.node.get_content()}, Score: {node.score}\")\n",
    "    print(\"######################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe257",
   "metadata": {},
   "source": [
    "## KeywordNodePostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c000c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.069395</td>\n",
       "      <td>Many great models are being introduced  <br>now a days that are h aving quite a heavy impact on the field on NLP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.301733</td>\n",
       "      <td>Sentiment analysis is a natural  language  <br>processing (NLP) technique used to determine whether data is positive, negative or neutral.  <br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.241898</td>\n",
       "      <td>Opinion Analysis is an NLP and data extract ion <br>task that expects to acquire essayists felling <br>communicated in certain or negative remarks, <br>questions, and demands by breaking down an enormous  <br>number of archives.  <br></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Many great models are being introduced  \n",
      "now a days that are h aving quite a heavy impact on the field on NLP. \n",
      "######################\n",
      "Sentiment analysis is a natural  language  \n",
      "processing (NLP) technique used to determine whether data is positive, negative or neutral.  \n",
      "\n",
      "######################\n",
      "Opinion Analysis is an NLP and data extract ion \n",
      "task that expects to acquire essayists felling \n",
      "communicated in certain or negative remarks, \n",
      "questions, and demands by breaking down an enormous  \n",
      "number of archives.  \n",
      "\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.postprocessor import KeywordNodePostprocessor\n",
    "\n",
    "postprocessor = KeywordNodePostprocessor(\n",
    "  required_keywords=[\"NLP\"]\n",
    ")\n",
    "\n",
    "re=postprocessor.postprocess_nodes(retrieved_nodes)\n",
    "visualize_retrieved_nodes(re)\n",
    "\n",
    "print(len(re))\n",
    "for i in re:\n",
    "    print(i.text)\n",
    "    print(\"######################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8650a22",
   "metadata": {},
   "source": [
    "## Custom Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cc9ae61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>{\"relevance_score\": 0.75}</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>{\"relevance_score\": 0.75}</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>{\"relevance_score\": 0.0}</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>{\"relevance_score\": 0.45}</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textA = response\n",
    "for i in retrieved_nodes:\n",
    "    textB = i.text\n",
    "    prompt=f\"\"\"you are a expert in text evaluation.\n",
    "        I want you to compare two texts and return a relevance score of text A to text B.\n",
    "        textA : {textA},\n",
    "        textB : {textB},\n",
    "        return the relevance score in json format\n",
    "    \"\"\"\n",
    "    eval = query_engine.query(prompt)\n",
    "    display(Markdown(f\"<b>{eval}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3a6dc",
   "metadata": {},
   "source": [
    "## evaluation techniques\n",
    "### 1. Mean average precision (MAP)\n",
    "### 2. Mean Reciprocal Rank (MRR)\n",
    "### 3. Normalize Discounted Comulative Gain (NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_true = [...]  # replace with your ground truth labels\n",
    "y_scores = [...]  # replace with your predicted scores\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "import torch\n",
    "from torchmetrics import RetrievalMAP\n",
    "\n",
    "map_metric = RetrievalMAP()\n",
    "retrieval_scores = torch.tensor(y_scores)\n",
    "relevant_docs = torch.tensor(y_true)\n",
    "map_val = map_metric(retrieval_scores, relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edebf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
